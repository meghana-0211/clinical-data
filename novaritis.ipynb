{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNreARd3DJekRLp1Xe2JD2Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meghana-0211/clinical-data/blob/main/novaritis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNAzh2Jh0b6f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from typing import List, Dict, Any\n",
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "class ClinicalTrialsPreprocessor:\n",
        "    def __init__(self,\n",
        "                 usecase_csv: str,\n",
        "                 facilities_txt: str,\n",
        "                 drop_withdrawals_txt: str,\n",
        "                 eligibilities_txt: str,\n",
        "                 reported_events_txt: str):\n",
        "        \"\"\"\n",
        "        Advanced preprocessor for clinical trials data\n",
        "\n",
        "        Args:\n",
        "            usecase_csv (str): Path to main usecase CSV\n",
        "            facilities_txt (str): Path to facilities text file\n",
        "            drop_withdrawals_txt (str): Path to withdrawals text file\n",
        "            eligibilities_txt (str): Path to eligibilities text file\n",
        "            reported_events_txt (str): Path to reported events text file\n",
        "        \"\"\"\n",
        "        # Flexible delimiter and column detection\n",
        "        self.df_main = self._read_file(usecase_csv)\n",
        "        self.df_facilities = self._read_file(facilities_txt)\n",
        "        self.df_withdrawals = self._read_file(drop_withdrawals_txt)\n",
        "        self.df_eligibility = self._read_file(eligibilities_txt)\n",
        "        self.df_reported_events = self._read_file(reported_events_txt)\n",
        "\n",
        "        # Preprocessing metadata\n",
        "        self.preprocessing_log = {}\n",
        "        self.feature_metadata = {}\n",
        "\n",
        "    def _read_file(self, filepath: str, delimiters=['|', '\\t', ',', ';']) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Intelligently read files with different potential delimiters\n",
        "\n",
        "        Args:\n",
        "            filepath (str): Path to the file\n",
        "            delimiters (list): List of delimiters to try\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: Loaded dataframe\n",
        "        \"\"\"\n",
        "        for delimiter in delimiters:\n",
        "            try:\n",
        "                df = pd.read_csv(filepath, sep=delimiter, low_memory=False)\n",
        "                return df\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        raise ValueError(f\"Could not read file {filepath} with standard delimiters\")\n",
        "\n",
        "    def _find_nct_column(self, df: pd.DataFrame) -> str:\n",
        "        \"\"\"\n",
        "        Find the NCT ID column in a dataframe\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): Input dataframe\n",
        "\n",
        "        Returns:\n",
        "            str: Name of the NCT ID column\n",
        "        \"\"\"\n",
        "        possible_columns = ['nct_id', 'NCT_ID', 'nct number', 'NCT Number', 'NCT number', 'id', 'Unnamed: 1']\n",
        "        for col in possible_columns:\n",
        "            if col in df.columns:\n",
        "                return col\n",
        "        raise ValueError(f\"No NCT ID column found. Available columns: {list(df.columns)}\")\n",
        "\n",
        "    def clean_nct_id(self, id_str: str) -> str:\n",
        "        \"\"\"\n",
        "        Enhanced NCT ID cleaning with more robust validation\n",
        "\n",
        "        Args:\n",
        "            id_str (str): Input ID string\n",
        "\n",
        "        Returns:\n",
        "            str: Cleaned and standardized NCT ID\n",
        "        \"\"\"\n",
        "        if pd.isna(id_str):\n",
        "            return np.nan\n",
        "\n",
        "        # Convert to string and strip\n",
        "        id_str = str(id_str).strip()\n",
        "\n",
        "        # Remove any non-digit characters\n",
        "        numeric_part = re.sub(r'\\D', '', id_str)\n",
        "\n",
        "        # Pad to 8 digits if needed\n",
        "        padded_numeric = numeric_part.zfill(8)\n",
        "\n",
        "        return f'NCT{padded_numeric}'\n",
        "\n",
        "    def _preprocess_nct_ids(self):\n",
        "        \"\"\"\n",
        "        Preprocess NCT IDs across all dataframes\n",
        "        \"\"\"\n",
        "        # Find and clean NCT ID columns\n",
        "        dataframes = [\n",
        "            self.df_main,\n",
        "            self.df_facilities,\n",
        "            self.df_withdrawals,\n",
        "            self.df_eligibility,\n",
        "            self.df_reported_events\n",
        "        ]\n",
        "\n",
        "        for df in dataframes:\n",
        "            try:\n",
        "                nct_col = self._find_nct_column(df)\n",
        "                df['Clean_NCT_Number'] = df[nct_col].apply(self.clean_nct_id)\n",
        "            except ValueError:\n",
        "                print(f\"Could not find NCT ID column in dataframe: {list(df.columns)}\")\n",
        "\n",
        "    def extract_advanced_features(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Extract advanced features from text fields\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: Dataframe with extracted features\n",
        "        \"\"\"\n",
        "        def parse_criteria(criteria: str) -> Dict[str, int]:\n",
        "            \"\"\"\n",
        "            Parse inclusion/exclusion criteria\n",
        "\n",
        "            Args:\n",
        "                criteria (str): Criteria text\n",
        "\n",
        "            Returns:\n",
        "                Dict of feature counts\n",
        "            \"\"\"\n",
        "            if pd.isna(criteria):\n",
        "                return {}\n",
        "\n",
        "            features = {\n",
        "                'inclusion_count': len(re.findall(r'\\*\\s*Inclusion', str(criteria), re.IGNORECASE)),\n",
        "                'exclusion_count': len(re.findall(r'\\*\\s*Exclusion', str(criteria), re.IGNORECASE)),\n",
        "                'has_age_restriction': bool(re.search(r'(age|years)', str(criteria), re.IGNORECASE)),\n",
        "                'has_health_condition': bool(re.search(r'(condition|disease|syndrome)', str(criteria), re.IGNORECASE))\n",
        "            }\n",
        "            return features\n",
        "\n",
        "        # Extract features from eligibility criteria\n",
        "        try:\n",
        "            eligibility_features = self.df_eligibility['criteria'].apply(parse_criteria).apply(pd.Series)\n",
        "        except KeyError:\n",
        "            print(\"No 'criteria' column found in eligibility dataframe\")\n",
        "            eligibility_features = pd.DataFrame()\n",
        "\n",
        "        return eligibility_features\n",
        "\n",
        "    def handle_missing_values(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Advanced missing value handling\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): Input dataframe\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: Dataframe with handled missing values\n",
        "        \"\"\"\n",
        "        # Log missing values before processing\n",
        "        missing_before = df.isnull().sum()\n",
        "\n",
        "        # Imputation strategies\n",
        "        numeric_imputer = SimpleImputer(strategy='median')\n",
        "        categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "        # Identify column types\n",
        "        numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "        categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "        # Impute missing values\n",
        "        df[numeric_cols] = numeric_imputer.fit_transform(df[numeric_cols])\n",
        "        df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])\n",
        "\n",
        "        # Log missing values after processing\n",
        "        missing_after = df.isnull().sum()\n",
        "\n",
        "        # Store imputation metadata\n",
        "        self.preprocessing_log['missing_values'] = {\n",
        "            'before': missing_before,\n",
        "            'after': missing_after\n",
        "        }\n",
        "\n",
        "        return df\n",
        "\n",
        "    def encode_categorical_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Advanced categorical feature encoding\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): Input dataframe\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: Dataframe with encoded categorical features\n",
        "        \"\"\"\n",
        "        # Identify categorical columns\n",
        "        categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "        # Target encoding for high cardinality features\n",
        "        try:\n",
        "            encoder = ce.TargetEncoder(cols=categorical_cols)\n",
        "            encoded_df = encoder.fit_transform(df, df['Enrollment'])\n",
        "        except Exception as e:\n",
        "            print(f\"Error in target encoding: {e}\")\n",
        "            encoded_df = df\n",
        "\n",
        "        return encoded_df\n",
        "\n",
        "    def normalize_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Normalize numerical features\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): Input dataframe\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: Normalized dataframe\n",
        "        \"\"\"\n",
        "        # Select numeric columns\n",
        "        numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "        # Standard scaling\n",
        "        scaler = StandardScaler()\n",
        "        df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
        "\n",
        "        return df\n",
        "\n",
        "    def merge_with_additional_data(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Comprehensive merge of multiple data sources\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: Merged and preprocessed dataframe\n",
        "        \"\"\"\n",
        "        # Preprocess NCT IDs\n",
        "        self._preprocess_nct_ids()\n",
        "\n",
        "        # Merge dataframes\n",
        "        merged_df = self.df_main.copy()\n",
        "\n",
        "        # Merge configurations\n",
        "        merge_configs = [\n",
        "            (self.df_facilities, ['Clean_NCT_Number'],\n",
        "             ['name', 'city', 'state', 'country'], 'left'),\n",
        "            (self.df_withdrawals, ['Clean_NCT_Number'],\n",
        "             ['reason', 'count'], 'left'),\n",
        "            (self.df_eligibility, ['Clean_NCT_Number'],\n",
        "             ['gender', 'minimum_age', 'maximum_age'], 'left'),\n",
        "            (self.df_reported_events, ['Clean_NCT_Number'],\n",
        "             ['event_type', 'subjects_affected'], 'left')\n",
        "        ]\n",
        "\n",
        "        # Perform merges\n",
        "        for txt_df, merge_cols, selected_cols, merge_type in merge_configs:\n",
        "            try:\n",
        "                available_cols = [col for col in selected_cols if col in txt_df.columns]\n",
        "                if available_cols:\n",
        "                    merged_df = merged_df.merge(\n",
        "                        txt_df[merge_cols + available_cols],\n",
        "                        on=merge_cols[0],\n",
        "                        how=merge_type\n",
        "                    )\n",
        "            except Exception as e:\n",
        "                print(f\"Error merging {txt_df}: {e}\")\n",
        "\n",
        "        return merged_df\n",
        "\n",
        "    def preprocess(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Comprehensive preprocessing pipeline\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: Fully preprocessed dataframe\n",
        "        \"\"\"\n",
        "        # Merge data sources\n",
        "        merged_df = self.merge_with_additional_data()\n",
        "\n",
        "        # Extract advanced features\n",
        "        advanced_features = self.extract_advanced_features()\n",
        "        if not advanced_features.empty:\n",
        "            merged_df = pd.concat([merged_df, advanced_features], axis=1)\n",
        "\n",
        "        # Handle missing values\n",
        "        merged_df = self.handle_missing_values(merged_df)\n",
        "\n",
        "        # Encode categorical features\n",
        "        merged_df = self.encode_categorical_features(merged_df)\n",
        "\n",
        "        # Normalize features\n",
        "        merged_df = self.normalize_features(merged_df)\n",
        "\n",
        "        return merged_df\n",
        "\n",
        "    def generate_data_report(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Generate comprehensive data preprocessing report\n",
        "\n",
        "        Returns:\n",
        "            Dict with preprocessing metadata\n",
        "        \"\"\"\n",
        "        report = {\n",
        "            'initial_shape': self.df_main.shape,\n",
        "            'merged_shape': None,\n",
        "            'missing_values': self.preprocessing_log.get('missing_values', {}),\n",
        "            'unique_nct_ids': {\n",
        "                'original': self.df_main['NCT Number'].nunique() if 'NCT Number' in self.df_main.columns else 'N/A',\n",
        "                'cleaned': None\n",
        "            },\n",
        "            'feature_stats': {}\n",
        "        }\n",
        "\n",
        "        return report\n",
        "\n",
        "# Main processing function\n",
        "def process_clinical_trials(\n",
        "    usecase_csv: str,\n",
        "    facilities_txt: str,\n",
        "    drop_withdrawals_txt: str,\n",
        "    eligibilities_txt: str,\n",
        "    reported_events_txt: str\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Main processing function\n",
        "\n",
        "    Args:\n",
        "        usecase_csv (str): Path to main CSV\n",
        "        facilities_txt (str): Path to facilities text file\n",
        "        drop_withdrawals_txt (str): Path to withdrawals text file\n",
        "        eligibilities_txt (str): Path to eligibilities text file\n",
        "        reported_events_txt (str): Path to reported events text file\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Preprocessed dataframe\n",
        "    \"\"\"\n",
        "    preprocessor = ClinicalTrialsPreprocessor(\n",
        "        usecase_csv,\n",
        "        facilities_txt,\n",
        "        drop_withdrawals_txt,\n",
        "        eligibilities_txt,\n",
        "        reported_events_txt\n",
        "    )\n",
        "\n",
        "    # Preprocess data\n",
        "    processed_df = preprocessor.preprocess()\n",
        "\n",
        "    # Generate report\n",
        "    report = preprocessor.generate_data_report()\n",
        "    print(\"Preprocessing Report:\")\n",
        "    for key, value in report.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "    return processed_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install category_encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPtHTH6Y8jw3",
        "outputId": "dee38e60-544a-4c29-b9b3-e63209117ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.8.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.13.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.5.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Downloading category_encoders-2.8.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "processed_data = process_clinical_trials(\n",
        "    '/content/drive/MyDrive/usecase_1_.csv',\n",
        "    '/content/drive/MyDrive/facilities.txt',\n",
        "    '/content/drive/MyDrive/drop_withdrawals.txt',\n",
        "    '/content/drive/MyDrive/eligibilities.txt',\n",
        "    '/content/drive/MyDrive/reported_events.txt'\n",
        ")\n",
        "\n",
        "# Save processed data\n",
        "processed_data.to_csv('/content/drive/MyDrive/advanced_processed_clinical_trials.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0-KnBcu7RRU",
        "outputId": "4a4ad2b0-88f9-4e1a-ed57-36ec7e864c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Could not find NCT ID column in dataframe: [',Unnamed: 0,NCT Number,Study Title,Study URL,Acronym,Study Status,Brief Summary,Study Results,Conditions,Interventions,Primary Outcome Measures,Secondary Outcome Measures,Other Outcome Measures,Sponsor,Collaborators,Sex,Age,Phases,Enrollment,Funder Type,Study Type,Study Design,Other IDs,Start Date,Primary Completion Date,Completion Date,First Posted,Results First Posted,Last Update Posted,Locations,Study Documents']\n",
            "Error merging                id       nct_id      status  \\\n",
            "0        39182239  NCT02696421  RECRUITING   \n",
            "1        39182240  NCT01324414         NaN   \n",
            "2        39182241  NCT02595814         NaN   \n",
            "3        39182242  NCT02595814         NaN   \n",
            "4        39182243  NCT02595814         NaN   \n",
            "...           ...          ...         ...   \n",
            "3085459  39182234  NCT05770505         NaN   \n",
            "3085460  39182235  NCT00127790         NaN   \n",
            "3085461  39182236  NCT02577705         NaN   \n",
            "3085462  39182237  NCT01518205         NaN   \n",
            "3085463  39182238  NCT05600790         NaN   \n",
            "\n",
            "                                                      name           city  \\\n",
            "0                  Imperial College London Diabetes Centre      Abu Dhabi   \n",
            "1                                              Mayo Clinic        Phoenix   \n",
            "2                              Novartis Investigative Site      San Diego   \n",
            "3                              Novartis Investigative Site  San Francisco   \n",
            "4                              Novartis Investigative Site        Chicago   \n",
            "...                                                    ...            ...   \n",
            "3085459  Norwegian University of Science and Technology...      Trondheim   \n",
            "3085460  University of Rochester Sleep Research Laboratory      Rochester   \n",
            "3085461          Drexel University School of Public Health   Philadelphia   \n",
            "3085462                                  universita Verona         Verona   \n",
            "3085463                                  Peking University        Beijing   \n",
            "\n",
            "                state         zip               country Clean_NCT_Number  \n",
            "0                 NaN       48338  United Arab Emirates      NCT02696421  \n",
            "1             Arizona       85054         United States      NCT01324414  \n",
            "2          California       92103         United States      NCT02595814  \n",
            "3          California  94143-0780         United States      NCT02595814  \n",
            "4            Illinois       60611         United States      NCT02595814  \n",
            "...               ...         ...                   ...              ...  \n",
            "3085459           NaN        7006                Norway      NCT05770505  \n",
            "3085460      New York       14642         United States      NCT00127790  \n",
            "3085461  Pennsylvania       19104         United States      NCT02577705  \n",
            "3085462           NaN       37100                 Italy      NCT01518205  \n",
            "3085463       Beijing      100871                 China      NCT05600790  \n",
            "\n",
            "[3085464 rows x 9 columns]: 'Clean_NCT_Number'\n",
            "Error merging              id       nct_id  result_group_id ctgov_group_code  \\\n",
            "0       5991139  NCT00827372          9120733            FG000   \n",
            "1       5991140  NCT00827372          9120733            FG000   \n",
            "2       5991141  NCT01982760          9120734            FG000   \n",
            "3       5991142  NCT01982760          9120735            FG001   \n",
            "4       5991143  NCT01056276          9120736            FG000   \n",
            "...         ...          ...              ...              ...   \n",
            "487394  5893459  NCT00409838          8965265            FG001   \n",
            "487395  5893460  NCT00409838          8965264            FG000   \n",
            "487396  5893461  NCT00409838          8965265            FG001   \n",
            "487397  5893462  NCT00409838          8965264            FG000   \n",
            "487398  5893463  NCT00409838          8965265            FG001   \n",
            "\n",
            "                             period                         reason  count  \\\n",
            "0                     Overall Study                  Adverse Event      5   \n",
            "1                     Overall Study               Lack of Efficacy      3   \n",
            "2                     Overall Study             Physician Decision      1   \n",
            "3                     Overall Study             Physician Decision      0   \n",
            "4       Treatment Period-Cycles 1-8                       Toxicity      2   \n",
            "...                             ...                            ...    ...   \n",
            "487394   Long-term Extension Period          Withdrawal by Subject      0   \n",
            "487395   Long-term Extension Period  Poor compliance/noncompliance      1   \n",
            "487396   Long-term Extension Period  Poor compliance/noncompliance      0   \n",
            "487397   Long-term Extension Period                      Pregnancy      1   \n",
            "487398   Long-term Extension Period                      Pregnancy      0   \n",
            "\n",
            "        drop_withdraw_comment  reason_comment  count_units Clean_NCT_Number  \n",
            "0                         NaN             NaN          NaN      NCT00827372  \n",
            "1                         NaN             NaN          NaN      NCT00827372  \n",
            "2                         NaN             NaN          NaN      NCT01982760  \n",
            "3                         NaN             NaN          NaN      NCT01982760  \n",
            "4                         NaN             NaN          NaN      NCT01056276  \n",
            "...                       ...             ...          ...              ...  \n",
            "487394                    NaN             NaN          NaN      NCT00409838  \n",
            "487395                    NaN             NaN          NaN      NCT00409838  \n",
            "487396                    NaN             NaN          NaN      NCT00409838  \n",
            "487397                    NaN             NaN          NaN      NCT00409838  \n",
            "487398                    NaN             NaN          NaN      NCT00409838  \n",
            "\n",
            "[487399 rows x 11 columns]: 'Clean_NCT_Number'\n",
            "Error merging              id       nct_id sampling_method  gender minimum_age maximum_age  \\\n",
            "0       6260055  NCT05050916             NaN  FEMALE    19 Years    40 Years   \n",
            "1       6260056  NCT01092156             NaN  FEMALE    18 Years         NaN   \n",
            "2       6260057  NCT01218256             NaN     ALL    30 Years    80 Years   \n",
            "3       6260058  NCT03240432             NaN     ALL    60 Years         NaN   \n",
            "4       6260059  NCT04348578             NaN     ALL    18 Years    65 Years   \n",
            "...         ...          ...             ...     ...         ...         ...   \n",
            "502296  6259966  NCT02723058             NaN  FEMALE    18 Years         NaN   \n",
            "502297  6259967  NCT05832216             NaN     ALL    12 Years         NaN   \n",
            "502298  6259968  NCT05199597             NaN     ALL    18 Years         NaN   \n",
            "502299  6259969  NCT01583283             NaN     ALL    18 Years         NaN   \n",
            "502300  6259970  NCT01394783             NaN     ALL         NaN      1 Year   \n",
            "\n",
            "       healthy_volunteers population  \\\n",
            "0                       f        NaN   \n",
            "1                       t        NaN   \n",
            "2                       f        NaN   \n",
            "3                       t        NaN   \n",
            "4                       t        NaN   \n",
            "...                   ...        ...   \n",
            "502296                  f        NaN   \n",
            "502297                  f        NaN   \n",
            "502298                  t        NaN   \n",
            "502299                  f        NaN   \n",
            "502300                  f        NaN   \n",
            "\n",
            "                                                 criteria gender_description  \\\n",
            "0       * INCLUSION CRITERIA:~In order to be eligible ...                NaN   \n",
            "1       Inclusion Criteria:~* Pregnant women who inten...                NaN   \n",
            "2       Inclusion Criteria:~* type 2 diabetes mellitus...                NaN   \n",
            "3       Inclusion Criteria:~To be eligible for the stu...                NaN   \n",
            "4       Inclusion Criteria:~* necrotic, single root te...                NaN   \n",
            "...                                                   ...                ...   \n",
            "502296  Inclusion Criteria:~* Mothers who are residing...                NaN   \n",
            "502297  Inclusion Criteria:~* Diagnosis of aplastic an...                NaN   \n",
            "502298  Inclusion Criteria:~* 18 years and older~Exclu...                NaN   \n",
            "502299  Inclusion Criteria:~* Relapsed or Relapsed/Ref...                NaN   \n",
            "502300  Inclusion Criteria:~* Trainees: All residents ...                NaN   \n",
            "\n",
            "       gender_based adult child older_adult Clean_NCT_Number  \n",
            "0               NaN     t     f           f      NCT05050916  \n",
            "1               NaN     t     f           t      NCT01092156  \n",
            "2               NaN     t     f           t      NCT01218256  \n",
            "3               NaN     t     f           t      NCT03240432  \n",
            "4               NaN     t     f           t      NCT04348578  \n",
            "...             ...   ...   ...         ...              ...  \n",
            "502296          NaN     t     f           t      NCT02723058  \n",
            "502297          NaN     t     t           t      NCT05832216  \n",
            "502298          NaN     t     f           t      NCT05199597  \n",
            "502299          NaN     t     f           t      NCT01583283  \n",
            "502300          NaN     f     t           f      NCT01394783  \n",
            "\n",
            "[502301 rows x 15 columns]: 'Clean_NCT_Number'\n",
            "Error merging                 id       nct_id  result_group_id ctgov_group_code  \\\n",
            "0        111888450  NCT03978520          8932081            EG002   \n",
            "1        111888451  NCT03978520          8932082            EG003   \n",
            "2        111888452  NCT03978520          8932083            EG004   \n",
            "3        111888453  NCT03978520          8932079            EG000   \n",
            "4        111888454  NCT03978520          8932080            EG001   \n",
            "...            ...          ...              ...              ...   \n",
            "9284462  117455296  NCT03535727          9370737            EG004   \n",
            "9284463  117455297  NCT03535727          9370738            EG005   \n",
            "9284464  117455298  NCT03535727          9370739            EG006   \n",
            "9284465  117455299  NCT03535727          9370740            EG007   \n",
            "9284466  117455300  NCT03535727          9370741            EG008   \n",
            "\n",
            "                                                time_frame event_type  \\\n",
            "0        All-cause mortality is reported from enrollmen...      other   \n",
            "1        All-cause mortality is reported from enrollmen...      other   \n",
            "2        All-cause mortality is reported from enrollmen...      other   \n",
            "3        All-cause mortality is reported from enrollmen...      other   \n",
            "4        All-cause mortality is reported from enrollmen...      other   \n",
            "...                                                    ...        ...   \n",
            "9284462  All-Cause Mortality was assessed for up to 51 ...    serious   \n",
            "9284463  All-Cause Mortality was assessed for up to 51 ...    serious   \n",
            "9284464  All-Cause Mortality was assessed for up to 51 ...    serious   \n",
            "9284465  All-Cause Mortality was assessed for up to 51 ...    serious   \n",
            "9284466  All-Cause Mortality was assessed for up to 51 ...    serious   \n",
            "\n",
            "         default_vocab  default_assessment  subjects_affected  \\\n",
            "0                  NaN                 NaN                4.0   \n",
            "1                  NaN                 NaN                0.0   \n",
            "2                  NaN                 NaN                0.0   \n",
            "3                  NaN                 NaN                1.0   \n",
            "4                  NaN                 NaN                4.0   \n",
            "...                ...                 ...                ...   \n",
            "9284462            NaN                 NaN                2.0   \n",
            "9284463            NaN                 NaN                1.0   \n",
            "9284464            NaN                 NaN                0.0   \n",
            "9284465            NaN                 NaN                0.0   \n",
            "9284466            NaN                 NaN                2.0   \n",
            "\n",
            "         subjects_at_risk                                        description  \\\n",
            "0                      62  TEAEs and SAEs were collected from first dose ...   \n",
            "1                      69  TEAEs and SAEs were collected from first dose ...   \n",
            "2                      67  TEAEs and SAEs were collected from first dose ...   \n",
            "3                      75  TEAEs and SAEs were collected from first dose ...   \n",
            "4                      68  TEAEs and SAEs were collected from first dose ...   \n",
            "...                   ...                                                ...   \n",
            "9284462                 6  This study used the descriptions and grading s...   \n",
            "9284463                 3  This study used the descriptions and grading s...   \n",
            "9284464                 3  This study used the descriptions and grading s...   \n",
            "9284465                 7  This study used the descriptions and grading s...   \n",
            "9284466                 8  This study used the descriptions and grading s...   \n",
            "\n",
            "         event_count                            organ_system  \\\n",
            "0                4.0                   Psychiatric disorders   \n",
            "1                0.0                   Psychiatric disorders   \n",
            "2                0.0                   Psychiatric disorders   \n",
            "3                2.0  Skin and subcutaneous tissue disorders   \n",
            "4                4.0  Skin and subcutaneous tissue disorders   \n",
            "...              ...                                     ...   \n",
            "9284462          2.0                      Vascular disorders   \n",
            "9284463          1.0                      Vascular disorders   \n",
            "9284464          0.0                      Vascular disorders   \n",
            "9284465          0.0                      Vascular disorders   \n",
            "9284466          2.0                      Vascular disorders   \n",
            "\n",
            "           adverse_event_term  frequency_threshold        vocab  \\\n",
            "0                    INSOMNIA                    5  MedDRA 25.0   \n",
            "1                    INSOMNIA                    5  MedDRA 25.0   \n",
            "2                    INSOMNIA                    5  MedDRA 25.0   \n",
            "3                        ACNE                    5  MedDRA 25.0   \n",
            "4                        ACNE                    5  MedDRA 25.0   \n",
            "...                       ...                  ...          ...   \n",
            "9284462  Thromboembolic event                    5          NaN   \n",
            "9284463  Thromboembolic event                    5          NaN   \n",
            "9284464  Thromboembolic event                    5          NaN   \n",
            "9284465  Thromboembolic event                    5          NaN   \n",
            "9284466  Thromboembolic event                    5          NaN   \n",
            "\n",
            "                    assessment Clean_NCT_Number  \n",
            "0        SYSTEMATIC_ASSESSMENT      NCT03978520  \n",
            "1        SYSTEMATIC_ASSESSMENT      NCT03978520  \n",
            "2        SYSTEMATIC_ASSESSMENT      NCT03978520  \n",
            "3        SYSTEMATIC_ASSESSMENT      NCT03978520  \n",
            "4        SYSTEMATIC_ASSESSMENT      NCT03978520  \n",
            "...                        ...              ...  \n",
            "9284462  SYSTEMATIC_ASSESSMENT      NCT03535727  \n",
            "9284463  SYSTEMATIC_ASSESSMENT      NCT03535727  \n",
            "9284464  SYSTEMATIC_ASSESSMENT      NCT03535727  \n",
            "9284465  SYSTEMATIC_ASSESSMENT      NCT03535727  \n",
            "9284466  SYSTEMATIC_ASSESSMENT      NCT03535727  \n",
            "\n",
            "[9284467 rows x 18 columns]: 'Clean_NCT_Number'\n",
            "Error in target encoding: 'Enrollment'\n",
            "Preprocessing Report:\n",
            "initial_shape: (282390, 1)\n",
            "merged_shape: None\n",
            "missing_values: {'before': ,Unnamed: 0,NCT Number,Study Title,Study URL,Acronym,Study Status,Brief Summary,Study Results,Conditions,Interventions,Primary Outcome Measures,Secondary Outcome Measures,Other Outcome Measures,Sponsor,Collaborators,Sex,Age,Phases,Enrollment,Funder Type,Study Type,Study Design,Other IDs,Start Date,Primary Completion Date,Completion Date,First Posted,Results First Posted,Last Update Posted,Locations,Study Documents    219914\n",
            "inclusion_count                                                                                                                                                                                                                                                                                                                                                                                                                          91\n",
            "exclusion_count                                                                                                                                                                                                                                                                                                                                                                                                                          91\n",
            "has_age_restriction                                                                                                                                                                                                                                                                                                                                                                                                                      91\n",
            "has_health_condition                                                                                                                                                                                                                                                                                                                                                                                                                     91\n",
            "dtype: int64, 'after': ,Unnamed: 0,NCT Number,Study Title,Study URL,Acronym,Study Status,Brief Summary,Study Results,Conditions,Interventions,Primary Outcome Measures,Secondary Outcome Measures,Other Outcome Measures,Sponsor,Collaborators,Sex,Age,Phases,Enrollment,Funder Type,Study Type,Study Design,Other IDs,Start Date,Primary Completion Date,Completion Date,First Posted,Results First Posted,Last Update Posted,Locations,Study Documents    0\n",
            "inclusion_count                                                                                                                                                                                                                                                                                                                                                                                                                      0\n",
            "exclusion_count                                                                                                                                                                                                                                                                                                                                                                                                                      0\n",
            "has_age_restriction                                                                                                                                                                                                                                                                                                                                                                                                                  0\n",
            "has_health_condition                                                                                                                                                                                                                                                                                                                                                                                                                 0\n",
            "dtype: int64}\n",
            "unique_nct_ids: {'original': 'N/A', 'cleaned': None}\n",
            "feature_stats: {}\n"
          ]
        }
      ]
    }
  ]
}